{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a862aae",
   "metadata": {},
   "source": [
    "# Random Forest Classification\n",
    "This exercise uses the Wisconsin breast cancer dataset (https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic). Features are computed from a digitized image of a fine needle aspirate of a breast mass. They describe characteristics of the cell nuclei present in the image. \n",
    "\n",
    "Use a Random Forest Classifier for a binary classification (benign vs. malignant)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751871aa",
   "metadata": {},
   "source": [
    "#### Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e2332e",
   "metadata": {},
   "source": [
    "Load libraries and dataset (via sklearn for convenience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6945ac8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    RocCurveDisplay\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58d6a53",
   "metadata": {},
   "source": [
    "Load and inspect the data. Is the dataset balanced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7c1381",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "\n",
    "# Convert numeric labels to meaningful class names\n",
    "y = pd.Series(data.target).map({0: \"Malignant\", 1: \"Benign\"})\n",
    "\n",
    "print(\"Feature matrix shape:\", X.shape)\n",
    "print(\"\\nClass distribution:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8007fefd",
   "metadata": {},
   "source": [
    "Train/test split: Test later how your predictions change if you don't use stratify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaaa4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=y #ensures similarity of class proportions in test and training data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69819d0",
   "metadata": {},
   "source": [
    "#### Default RF model\n",
    "Note that the RF's predictions are probabilities for a data point to be in a certain class (this is, what `predict_proba()` delivers). The threshold for predicting labels with `predict()` is 50%. \n",
    "\n",
    "Is 50% a good choice? You can try a different threshold like so:\\\n",
    "`y_scores = best_rf.predict_proba(X_test)[:, 1]`\\\n",
    "`threshold = 0.3`\\\n",
    "`y_pred_custom = np.where(y_scores > threshold, \"Benign\", \"Malignant\")`\\\n",
    "`confusion_matrix(y_test, y_pred_custom)`\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dd2e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_default = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf_default.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_default.predict(X_test) # based on the probability (threshold 50%)\n",
    "y_proba = rf_default.predict_proba(X_test)[:, 1] # the probabilities for a positive (needed for the ROC-AUC score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b783f509",
   "metadata": {},
   "source": [
    "Evaluation of the model's performance: ROC-AUC is the metric for binary classification, accuracy simply determines how many of the predictions were correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c078948",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Baseline Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Baseline ROC-AUC score:\", roc_auc_score(y_test, y_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d4b3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(rf_default, X_test, y_test)\n",
    "plt.title(\"Baseline Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a488f01",
   "metadata": {},
   "source": [
    "Demo: Cross validation matters. There is a difference between the splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aea8833",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = cross_val_score(\n",
    "    rf_default,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=5,\n",
    "    scoring=\"roc_auc\"\n",
    ")\n",
    "\n",
    "print(\"CV ROC-AUC scores:\", cv_scores)\n",
    "print(\"Mean CV ROC-AUC:\", np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6229daa",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning: Grid Search\n",
    "Using defined parameters, a Grid Search is performed. Not all hyperparameters of the model have been chosen for this (to save some time), and a limited number of options is given for each. You can play around with the values later and see how they impact the performance of the RF.\n",
    "\n",
    "Some notes on the selected parameters:\n",
    "- `n_estimators`: Number of trees. Too small: unstable!\n",
    "- `max_depth`: Tree complexity. Too deep: overfitting! None = grow until pure.\n",
    "- `min_samples_leaf`: Regularisation (prevents very specific splits). Larger = Smoother\n",
    "- `max_features`: Feature randomness for each split, controls correlation. Too large (None): trees similar, correlated features dominate.\n",
    "\n",
    "Simultaneous the GridSearchCV is simultaneously doing a CV and using the scores of that for the evaluation of the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441bfcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": [100, 300],\n",
    "    \"max_depth\": [None, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 3],\n",
    "    \"max_features\": [\"sqrt\", 0.5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73db84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    rf,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best CV ROC-AUC:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72b2471",
   "metadata": {},
   "source": [
    "Predict using the best estimator and evaluate the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae26f1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = grid.best_estimator_\n",
    "\n",
    "y_pred_tuned = best_rf.predict(X_test)\n",
    "y_proba_tuned = best_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Tuned Accuracy:\", accuracy_score(y_test, y_pred_tuned))\n",
    "print(\"Tuned ROC-AUC:\", roc_auc_score(y_test, y_proba_tuned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09728b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(best_rf, X_test, y_test)\n",
    "plt.title(\"Tuned Model Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8286da4a",
   "metadata": {},
   "source": [
    "##### Discussion\n",
    "- What is your take on the performance improvement? is this a relevant improvement?\n",
    "- Could the \"best\" model also be worse? \n",
    "- Was the improvement clinically relevant?\n",
    "- How important is accuracy in this context? \n",
    "- What could you to to improve on the false negatives? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8906c9cc",
   "metadata": {},
   "source": [
    "#### Feature importance\n",
    "\n",
    "See which features dominate the RF model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f168d2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = best_rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(range(10), importances[indices][:10])\n",
    "plt.xticks(range(10), X.columns[indices][:10], rotation=90)\n",
    "plt.title(\"Top 10 Feature Importances\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSA104",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
